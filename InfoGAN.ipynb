{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUe5bI6OJrcb",
        "outputId": "6f4c82c9-baf7-4070-b2fe-45cf6f67aae0"
      },
      "outputs": [],
      "source": [
        "%pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRtN2PcZKBsP",
        "outputId": "12d14227-e8d5-4e4d-9bde-b2684d14d77d"
      },
      "outputs": [],
      "source": [
        "%pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pvSxOuhJzlb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os, sys\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "from matplotlib.pyplot import imshow, imsave\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GulPCYeJKGrS"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'infoGAN'\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_U7GLoIJ-uj"
      },
      "outputs": [],
      "source": [
        "def to_onehot(x, num_classes=10):\n",
        "    assert isinstance(x, int) or isinstance(x, (torch.LongTensor, torch.cuda.LongTensor))\n",
        "    if isinstance(x, int):\n",
        "        c = torch.zeros(1, num_classes).long()\n",
        "        c[0][x] = 1\n",
        "    else:\n",
        "        x = x.cpu()\n",
        "        c = torch.LongTensor(x.size(0), num_classes)\n",
        "        c.zero_()\n",
        "        c.scatter_(1, x, 1) # dim, index, src value\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84DJUnSLKQvC"
      },
      "outputs": [],
      "source": [
        "def sample_noise(batch_size, n_noise, n_c_discrete, n_c_continuous, label=None, supervised=False):\n",
        "    z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
        "    if supervised:\n",
        "        c_discrete = to_onehot(label).to(DEVICE) # (B,10)\n",
        "    else:\n",
        "        c_discrete = to_onehot(torch.LongTensor(batch_size, 1).random_(0, n_c_discrete)).to(DEVICE) # (B,10)\n",
        "    c_continuous = torch.zeros(batch_size, n_c_continuous).uniform_(-1, 1).to(DEVICE) # (B,2)\n",
        "    c = torch.cat((c_discrete.float(), c_continuous), 1)\n",
        "    return z, c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLg_5qckKRgm"
      },
      "outputs": [],
      "source": [
        "def get_sample_image():\n",
        "    \"\"\"\n",
        "        save sample 100 images\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    # continuous code\n",
        "    for cc_type in range(2):\n",
        "        for num in range(10):\n",
        "            fix_z = torch.randn(1, n_noise)\n",
        "            z = fix_z.to(DEVICE)\n",
        "            cc = -1\n",
        "            for i in range(10):\n",
        "                cc += 0.2\n",
        "                c_discrete = to_onehot(num).to(DEVICE) # (B,10)\n",
        "                c_continuous = torch.zeros(1, n_c_continuous).to(DEVICE)\n",
        "                c_continuous.data[:,cc_type].add_(cc)\n",
        "                c = torch.cat((c_discrete.float(), c_continuous), 1)\n",
        "                y_hat = G(z, c)\n",
        "                line_img = torch.cat((line_img, y_hat.view(28, 28)), dim=1) if i > 0 else y_hat.view(28, 28)\n",
        "            all_img = torch.cat((all_img, line_img), dim=0) if num > 0 else line_img\n",
        "        img = all_img.cpu().data.numpy()\n",
        "        images.append(img)\n",
        "    # discrete code\n",
        "    for num in range(10):\n",
        "        c_discrete = to_onehot(num).to(DEVICE) # (B,10)\n",
        "        for i in range(10):\n",
        "            z = torch.randn(1, n_noise).to(DEVICE)\n",
        "            c_continuous = torch.zeros(1, n_c_continuous).to(DEVICE)\n",
        "            c = torch.cat((c_discrete.float(), c_continuous), 1)\n",
        "            y_hat = G(z, c)\n",
        "            line_img = torch.cat((line_img, y_hat.view(28, 28)), dim=1) if i > 0 else y_hat.view(28, 28)\n",
        "        all_img = torch.cat((all_img, line_img), dim=0) if num > 0 else line_img\n",
        "    img = all_img.cpu().data.numpy()\n",
        "    images.append(img)\n",
        "    return images[0], images[1], images[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PuyqqKqKVSm"
      },
      "outputs": [],
      "source": [
        "def log_gaussian(c, mu, var):\n",
        "    \"\"\"\n",
        "        criterion for Q(condition classifier)\n",
        "    \"\"\"\n",
        "    return -((c - mu)**2)/(2*var+1e-8) - 0.5*torch.log(2*np.pi*var+1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNXS_ypKKXnC"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "        Convolutional Discriminator for MNIST\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channel=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer1 = nn.Sequential(# 28 -> 14\n",
        "            nn.Conv2d(in_channel, 64, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1),from torchvision import datasets\n",
        "\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(# 14 -> 7\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(#\n",
        "            nn.Linear(128*7*7, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(0.1),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1024, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        y_ = self.layer1(x)\n",
        "        y_ = self.layer2(y_)\n",
        "        y_ = y_.view(y_.size(0), -1)\n",
        "        y_ = self.layer3(y_)\n",
        "        d = self.fc(y_) # Real / Fake        \n",
        "        return d, y_ # return with top layer features for Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOjsUB5EKaQH"
      },
      "outputs": [],
      "source": [
        "class Qrator(nn.Module):\n",
        "    \"\"\"\n",
        "        Regularization Network for increasing Mutual Information\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Qrator, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1024, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(128, 14),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Seperate code\n",
        "        c = self.fc(x)\n",
        "        c_discrete = torch.softmax(c[:, :10], dim=-1) # Digit Label {0~9}\n",
        "        c_mu = c[:, 10:12] # mu & var of Rotation & Thickness\n",
        "        c_var = c[:, 12:14].exp() # mu & var of Rotation & Thickness\n",
        "        return c_discrete, c_mu, c_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUBfUWowKcbc"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "        Convolutional Generator for MNIST\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=62, code_size=12, num_classes=784):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(input_size+code_size, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(1024, 7*7*128),\n",
        "            nn.BatchNorm1d(7*7*128),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(# input: 7 by 7, output: 14 by 14\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(# input: 14 by 14, output: 28 by 28\n",
        "            nn.ConvTranspose2d(64, 1, 4, stride=2, padding=1, bias=False),\n",
        "            nn.ReLU()\n",
        "            #nn.Tanh(),\n",
        "        )\n",
        "        \n",
        "    def forward(self, z, c):\n",
        "        z = z.view(z.size(0), -1)\n",
        "        c = c.view(c.size(0), -1)\n",
        "        noise = torch.cat((z, c), 1)\n",
        "#         print(noise.size())\n",
        "        x_ = self.layer1(noise)\n",
        "        x_ = self.layer2(x_)\n",
        "        x_ = x_.view(x_.size(0), 128, 7, 7)\n",
        "        x_ = self.layer3(x_)\n",
        "        x_ = self.layer4(x_)\n",
        "        return x_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbKp7PmeKfPu"
      },
      "outputs": [],
      "source": [
        "D = Discriminator().to(DEVICE)\n",
        "G = Generator().to(DEVICE)\n",
        "Q = Qrator().to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8c0UfnrKhfw"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5],\n",
        "                                std=[0.5])]\n",
        ")\n",
        "mnist = datasets.MNIST(root='./data/', train=True, transform=transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6NUZiE3KpXE"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "data_loader = DataLoader(dataset=mnist, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
        "bce_loss = nn.BCELoss()\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "D_opt = torch.optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.99))\n",
        "G_opt = torch.optim.Adam([{'params':G.parameters()}, {'params':Q.parameters()}], lr=1e-3, betas=(0.5, 0.99))\n",
        "max_epoch = 200 # need more than 200 epochs for training generator\n",
        "step = 0\n",
        "n_critic = 1 # for training more k steps about Discriminator\n",
        "n_noise = 62\n",
        "n_c_discrete, n_c_continuous = 10, 2\n",
        "\n",
        "D_labels = torch.ones([batch_size, 1]).to(DEVICE) # Discriminator Label to real\n",
        "D_fakes = torch.zeros([batch_size, 1]).to(DEVICE) # Discriminator Label to fake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJyW6jxiK37G"
      },
      "outputs": [],
      "source": [
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_UPHWMCMINW"
      },
      "outputs": [],
      "source": [
        "os.mkdir('samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVKOEPn0K51Y",
        "outputId": "5a4ab9e4-98ad-49c2-81ac-650d2d9c638d"
      },
      "outputs": [],
      "source": [
        "for epoch in range(max_epoch+1):\n",
        "    for idx, (images, labels) in enumerate(data_loader):\n",
        "        step += 1\n",
        "        labels = labels.view(batch_size, 1)\n",
        "        # Training Discriminator\n",
        "        x = images.to(DEVICE)\n",
        "        x_outputs, _, = D(x)\n",
        "        D_x_loss = bce_loss(x_outputs, D_labels)\n",
        "\n",
        "        z, c = sample_noise(batch_size, n_noise, n_c_discrete, n_c_continuous, label=labels, supervised=True)\n",
        "        z_outputs, _, = D(G(z, c))\n",
        "        D_z_loss = bce_loss(z_outputs, D_fakes)\n",
        "        D_loss = D_x_loss + D_z_loss\n",
        "        \n",
        "        D_opt.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_opt.step()\n",
        "\n",
        "        # Training Generator\n",
        "        z, c = sample_noise(batch_size, n_noise, n_c_discrete, n_c_continuous, label=labels, supervised=True)\n",
        "        c_discrete_label = torch.max(c[:, :-2], 1)[1].view(-1, 1)\n",
        "\n",
        "        z_outputs, features = D(G(z, c)) # (B,1), (B,10), (B,4)\n",
        "        c_discrete_out, cc_mu, cc_var = Q(features)\n",
        "\n",
        "        G_loss = bce_loss(z_outputs, D_labels)\n",
        "        Q_loss_discrete = ce_loss(c_discrete_out, c_discrete_label.view(-1))\n",
        "        Q_loss_continuous = -torch.mean(torch.sum(log_gaussian(c[:, -2:], cc_mu, cc_var), 1)) # N(x | mu,var) -> (B, 2) -> (,1)\n",
        "        mutual_info_loss = Q_loss_discrete + Q_loss_continuous*0.1\n",
        "\n",
        "        GnQ_loss = G_loss + mutual_info_loss\n",
        "\n",
        "        G_opt.zero_grad()\n",
        "        GnQ_loss.backward()\n",
        "        G_opt.step()\n",
        "\n",
        "        if step > 500 and step % 100 == 0:\n",
        "            writer.add_scalar('loss/total', GnQ_loss, step)\n",
        "            writer.add_scalar('loss/Q_discrete', Q_loss_discrete, step)\n",
        "            writer.add_scalar('loss/Q_continuous', Q_loss_continuous, step)\n",
        "            writer.add_scalar('loss/Q', mutual_info_loss, step)\n",
        "            writer.add_histogram('output/mu', cc_mu)\n",
        "            writer.add_histogram('output/var', cc_var)\n",
        "        \n",
        "        if step % 500 == 0:\n",
        "            print('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}, GnQ Loss: {}, Time: {}'\\\n",
        "                  .format(epoch, max_epoch, step, D_loss.item(), G_loss.item(), GnQ_loss.item(), str(datetime.datetime.today())[:-7]))\n",
        "            \n",
        "        if step % 1000 == 0:\n",
        "            G.eval()\n",
        "            img1, img2, img3 = get_sample_image()\n",
        "            imsave('samples/{}_step{}_type1.jpg'.format(MODEL_NAME, str(step).zfill(3)), img1, cmap='gray')\n",
        "            imsave('samples/{}_step{}_type2.jpg'.format(MODEL_NAME, str(step).zfill(3)), img2, cmap='gray')\n",
        "            imsave('samples/{}_step{}_type3.jpg'.format(MODEL_NAME, str(step).zfill(3)), img3, cmap='gray')\n",
        "            G.train()\n",
        "writer.export_scalars_to_json(\"./all_summary.json\")\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hzI_nIrnK9U2",
        "outputId": "7ffbb73c-cfa7-4472-a553-25e325463de0"
      },
      "outputs": [],
      "source": [
        "# generation to image\n",
        "G.eval()\n",
        "imshow(get_sample_image()[0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E7spV6sYRgZz",
        "outputId": "102095f9-32bd-40a0-ae95-9a8bcf9f6cfc"
      },
      "outputs": [],
      "source": [
        "imshow(get_sample_image()[2], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9uG2yrw7TAvh",
        "outputId": "2385b566-895c-4681-9441-309d824c5178"
      },
      "outputs": [],
      "source": [
        "imshow(get_sample_image()[1], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcEh7M_XRlcu"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, file_name='checkpoint.pth.tar'):\n",
        "    torch.save(state, file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "2kBvdbiHRtVS",
        "outputId": "d7eb8391-587e-4ced-991a-d4c9cb7c1467"
      },
      "outputs": [],
      "source": [
        "# Saving params.\n",
        "# torch.save(D.state_dict(), 'D_c.pkl')\n",
        "# torch.save(G.state_dict(), 'G_c.pkl')\n",
        "save_checkpoint({'epoch': epoch + 1, 'state_dict':DnQ.state_dict(), 'optimizer' : DnQ_opt.state_dict()}, 'DnQ_info.pth.tar')\n",
        "save_checkpoint({'epoch': epoch + 1, 'state_dict':G.state_dict(), 'optimizer' : G_opt.state_dict()}, 'G_info.pth.tar')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "info2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "999bd6f6b42c287a72d5d73fa3c92a10a35ac3750e65bc80ca351872ad7d2ad4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
